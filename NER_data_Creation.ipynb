{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ea5964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bhanuprakash.d\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c4b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_set(in_list):\n",
    "    out_list = []\n",
    "    added = set()\n",
    "    for val in in_list:\n",
    "        if not val in added:\n",
    "            out_list.append(val)\n",
    "            added.add(val)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0525c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=pd.read_pickle(\"umls_refined_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d376ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7880881\n"
     ]
    }
   ],
   "source": [
    "mw_list = []\n",
    "for k,v in metadata.items():\n",
    "    for x in v:\n",
    "        ws = x.split() \n",
    "        if len(ws) > 1:\n",
    "            tws = tuple(ws)\n",
    "            mw_list.append(tws)\n",
    "        \n",
    "mw_list = ordered_set(mw_list)\n",
    "###################################\n",
    "my_idx = {}\n",
    "for i,w in enumerate(mw_list):\n",
    "    my_idx[\" \".join(w)] = i\n",
    "print(len(my_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18081df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mw_list.pkl','wb') as f:\n",
    "    pickle.dump(mw_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12ea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_idx.pkl','wb') as f:\n",
    "    pickle.dump(my_idx,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e2bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_list=pd.read_pickle('mw_list.pkl')\n",
    "my_idx=pd.read_pickle('my_idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8d0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe = MWETokenizer(mw_list,separator=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4996bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1abd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spans(txt):\n",
    "    tokens=mwe.tokenize(word_tokenize(txt))\n",
    "    offset = 0\n",
    "    for token in tokens:\n",
    "        offset = txt.find(token, offset)\n",
    "        yield token, offset, offset+len(token)\n",
    "        offset += len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977d1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER_Data_list(sentences):\n",
    "    \n",
    "    \n",
    "    all_item = []\n",
    "\n",
    "    for i in tqdm(range(len(sentences))):\n",
    "        print(\"sentence\",i+1)\n",
    "        word_ls = []\n",
    "        for token in spans(sentences[i]):\n",
    "            my_tuple = token[0]\n",
    "            flag=False\n",
    "            for k,v in metadata.items():\n",
    "                if token[0] in v:\n",
    "                    #word_ls.append(my_tuple)\n",
    "                    flag=True\n",
    "                    subwords = token[0].split()\n",
    "                    pos_list = [nltk.pos_tag([w]) for w in subwords]\n",
    "                    tag_list = ['I-'+k]*len(pos_list)\n",
    "                    tag_list[0] = 'B-'+k \n",
    "\n",
    "\n",
    "                    for s,p,t in zip(subwords,pos_list,tag_list):           \n",
    "                        if type(p) == list:\n",
    "                            p = p[0][1]\n",
    "                            #print('list')\n",
    "                        new_item = dict({'Sentence #': i+1, 'Tag' : t, 'Word': s,'POS': p})\n",
    "                        all_item.append(new_item)\n",
    "                    break\n",
    "            if flag==False:  \n",
    "                my_pos = nltk.pos_tag([my_tuple])[0][1]\n",
    "                new_item = dict({'Sentence #': i+1, 'Tag' : 'O', 'Word': my_tuple.lower(),'POS': my_pos})\n",
    "                all_item.append(new_item)\n",
    "    return all_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46992ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bhanuprakash.d\\.conda\\envs\\test\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('English_Sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a576b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=list(data.sentences.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8148429",
   "metadata": {},
   "outputs": [],
   "source": [
    "listy=sentences[:100000]\n",
    "#NER_Data_list(listy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b89a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bhanuprakash.d\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickles Loaded\n",
      "mwe tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "from NER_Data_Preparator import NER_Data_list as ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b37470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ba12a5d6684a2b9d02be6cc3f1b380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result=ner(listy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337b6dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B-Population Group</td>\n",
       "      <td>person</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>another</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>B-Functional Concept</td>\n",
       "      <td>causes</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>B-Sign or Symptom</td>\n",
       "      <td>fever</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>B-Sign or Symptom</td>\n",
       "      <td>headache</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #                   Tag      Word  POS\n",
       "0           1    B-Population Group    person   NN\n",
       "1           1                     O        to   TO\n",
       "2           1                     O   another   DT\n",
       "3           1                     O       and   CC\n",
       "4           1  B-Functional Concept    causes  NNS\n",
       "5           1     B-Sign or Symptom     fever   NN\n",
       "6           1                     O         ,    ,\n",
       "7           1     B-Sign or Symptom  headache   NN\n",
       "8           1                     O         ,    ,\n",
       "9           1                     O       and   CC"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result=pd.DataFrame(result).fillna(method=\"ffill\")\n",
    "df_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49ff0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428441"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdb581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
